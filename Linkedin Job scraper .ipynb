{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver path\n",
    "driver = webdriver.Chrome()\n",
    "# Launch the browser and get to the Linkedin login page\n",
    "# Maximize Window\n",
    "driver.maximize_window() \n",
    "driver.minimize_window() \n",
    "driver.maximize_window() \n",
    "driver.switch_to.window(driver.current_window_handle)\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter to the site\n",
    "driver.get(\"https://www.linkedin.com/login\");\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login credentials\n",
    "username = driver.find_element(By.ID,'username')\n",
    "\n",
    "# enter email address\n",
    "username.send_keys('youremail@gmail.com')\n",
    "\n",
    "# entering password\n",
    "pword = driver.find_element(By.ID, 'password')\n",
    "\n",
    "pword.send_keys('Yourpassword')\n",
    "\n",
    "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to the Jobs button and click it\n",
    "driver.find_element(By.XPATH,\"//*[@id='global-nav']/div/nav/ul/li[3]/a\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "# Go to search results directly via link\n",
    "driver.get(\"https://www.linkedin.com/jobs/search/?geoId=105646813&keywords=junior%20data%20analyst&location=Spain\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links are being collected now\n",
      "collecting the links in the page:1\n",
      "collecting the links in the page:2\n",
      "collecting the links in the page:3\n",
      "collecting the links in the page:4\n",
      "collecting the links in the page:5\n",
      "collecting the links in the page:6\n",
      "collecting the links in the page:7\n",
      "collecting the links in the page:8\n",
      "collecting the links in the page:9\n",
      "collecting the links in the page:10\n",
      "Found224 links for job offers\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "# navigate 13 pages\n",
    "print('Links are being collected now')\n",
    "try:\n",
    "    for page in range(2,14):\n",
    "        time.sleep(5)\n",
    "        jobs_block = driver.find_element(By.CLASS_NAME,\"jobs-search-results-list\")\n",
    "        jobs_list= jobs_block.find_elements(By.CSS_SELECTOR, \".jobs-search-results__list-item\")\n",
    "        \n",
    "        for job in jobs_list:\n",
    "            \n",
    "            all_links = job.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "            for a in all_links:\n",
    "                \n",
    "                if str(a.get_attribute('href')).startswith(\"https://www.linkedin.com/jobs/view\") and a.get_attribute('href') not in links: \n",
    "                    links.append(a.get_attribute('href'))\n",
    "                else:\n",
    "                    pass\n",
    "            # scroll down for each job element\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", job)\n",
    "        print(f\"collecting the links in the page:{page-1}\")\n",
    "        # goto next page\n",
    "        driver.find_element(By.XPATH,f\"//button[@aria-label='Page {page}']\").click()\n",
    "        time.sleep(10)\n",
    "except:\n",
    "    pass\n",
    "print(\"Found\" + str(len(links)) + \" links for job offers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting the links and collecting information just started\n",
      "Scraping the Job Offer 1 DONE.\n",
      "Scraping the Job Offer 2\n",
      "Scraping the Job Offer 2 DONE.\n",
      "Scraping the Job Offer 3\n",
      "Scraping the Job Offer 3 DONE.\n",
      "Scraping the Job Offer 4\n",
      "Scraping the Job Offer 4 DONE.\n",
      "Scraping the Job Offer 5\n",
      "Scraping the Job Offer 5 DONE.\n",
      "Scraping the Job Offer 6\n",
      "Scraping the Job Offer 6 DONE.\n",
      "Scraping the Job Offer 7\n",
      "Scraping the Job Offer 7 DONE.\n",
      "Scraping the Job Offer 8\n",
      "Scraping the Job Offer 8 DONE.\n",
      "Scraping the Job Offer 9\n",
      "Scraping the Job Offer 9 DONE.\n",
      "Scraping the Job Offer 10\n",
      "Scraping the Job Offer 10 DONE.\n",
      "Scraping the Job Offer 11\n",
      "Scraping the Job Offer 11 DONE.\n",
      "Scraping the Job Offer 12\n",
      "Scraping the Job Offer 12 DONE.\n",
      "Scraping the Job Offer 13\n",
      "Scraping the Job Offer 13 DONE.\n",
      "Scraping the Job Offer 14\n",
      "Scraping the Job Offer 14 DONE.\n",
      "Scraping the Job Offer 15\n",
      "Scraping the Job Offer 15 DONE.\n",
      "Scraping the Job Offer 16\n",
      "Scraping the Job Offer 16\n",
      "Scraping the Job Offer 16 DONE.\n",
      "Scraping the Job Offer 17\n",
      "Scraping the Job Offer 17\n",
      "Scraping the Job Offer 17 DONE.\n",
      "Scraping the Job Offer 18\n",
      "Scraping the Job Offer 18 DONE.\n",
      "Scraping the Job Offer 19\n",
      "Scraping the Job Offer 19 DONE.\n",
      "Scraping the Job Offer 20\n",
      "Scraping the Job Offer 20 DONE.\n",
      "Scraping the Job Offer 21\n",
      "Scraping the Job Offer 21 DONE.\n",
      "Scraping the Job Offer 22\n",
      "Scraping the Job Offer 22 DONE.\n",
      "Scraping the Job Offer 23\n",
      "Scraping the Job Offer 23 DONE.\n",
      "Scraping the Job Offer 24\n",
      "Scraping the Job Offer 24 DONE.\n",
      "Scraping the Job Offer 25\n",
      "Scraping the Job Offer 25 DONE.\n",
      "Scraping the Job Offer 26\n",
      "Scraping the Job Offer 26 DONE.\n",
      "Scraping the Job Offer 27\n",
      "Scraping the Job Offer 27 DONE.\n",
      "Scraping the Job Offer 28\n",
      "Scraping the Job Offer 28 DONE.\n",
      "Scraping the Job Offer 29\n",
      "Scraping the Job Offer 29 DONE.\n",
      "Scraping the Job Offer 30\n",
      "Scraping the Job Offer 30 DONE.\n",
      "Scraping the Job Offer 31\n",
      "Scraping the Job Offer 31 DONE.\n",
      "Scraping the Job Offer 32\n",
      "Scraping the Job Offer 32 DONE.\n",
      "Scraping the Job Offer 33\n",
      "Scraping the Job Offer 33 DONE.\n",
      "Scraping the Job Offer 34\n",
      "Scraping the Job Offer 34 DONE.\n",
      "Scraping the Job Offer 35\n",
      "Scraping the Job Offer 35 DONE.\n",
      "Scraping the Job Offer 36\n",
      "Scraping the Job Offer 36 DONE.\n",
      "Scraping the Job Offer 37\n",
      "Scraping the Job Offer 37 DONE.\n",
      "Scraping the Job Offer 38\n",
      "Scraping the Job Offer 38 DONE.\n",
      "Scraping the Job Offer 39\n",
      "Scraping the Job Offer 39 DONE.\n",
      "Scraping the Job Offer 40\n",
      "Scraping the Job Offer 40 DONE.\n",
      "Scraping the Job Offer 41\n",
      "Scraping the Job Offer 41 DONE.\n",
      "Scraping the Job Offer 42\n",
      "Scraping the Job Offer 42 DONE.\n",
      "Scraping the Job Offer 43\n",
      "Scraping the Job Offer 43 DONE.\n",
      "Scraping the Job Offer 44\n",
      "Scraping the Job Offer 44 DONE.\n",
      "Scraping the Job Offer 45\n",
      "Scraping the Job Offer 45 DONE.\n",
      "Scraping the Job Offer 46\n",
      "Scraping the Job Offer 46 DONE.\n",
      "Scraping the Job Offer 47\n",
      "Scraping the Job Offer 47 DONE.\n",
      "Scraping the Job Offer 48\n",
      "Scraping the Job Offer 48 DONE.\n",
      "Scraping the Job Offer 49\n",
      "Scraping the Job Offer 49 DONE.\n",
      "Scraping the Job Offer 50\n",
      "Scraping the Job Offer 50 DONE.\n",
      "Scraping the Job Offer 51\n",
      "Scraping the Job Offer 51 DONE.\n",
      "Scraping the Job Offer 52\n",
      "Scraping the Job Offer 52 DONE.\n",
      "Scraping the Job Offer 53\n",
      "Scraping the Job Offer 53 DONE.\n",
      "Scraping the Job Offer 54\n",
      "Scraping the Job Offer 54 DONE.\n",
      "Scraping the Job Offer 55\n",
      "Scraping the Job Offer 55 DONE.\n",
      "Scraping the Job Offer 56\n",
      "Scraping the Job Offer 56 DONE.\n",
      "Scraping the Job Offer 57\n",
      "Scraping the Job Offer 57 DONE.\n",
      "Scraping the Job Offer 58\n",
      "Scraping the Job Offer 58 DONE.\n",
      "Scraping the Job Offer 59\n",
      "Scraping the Job Offer 59 DONE.\n",
      "Scraping the Job Offer 60\n",
      "Scraping the Job Offer 60 DONE.\n",
      "Scraping the Job Offer 61\n",
      "Scraping the Job Offer 61 DONE.\n",
      "Scraping the Job Offer 62\n",
      "Scraping the Job Offer 62 DONE.\n",
      "Scraping the Job Offer 63\n",
      "Scraping the Job Offer 63 DONE.\n",
      "Scraping the Job Offer 64\n",
      "Scraping the Job Offer 64 DONE.\n",
      "Scraping the Job Offer 65\n",
      "Scraping the Job Offer 65 DONE.\n",
      "Scraping the Job Offer 66\n",
      "Scraping the Job Offer 66 DONE.\n",
      "Scraping the Job Offer 67\n",
      "Scraping the Job Offer 67 DONE.\n",
      "Scraping the Job Offer 68\n",
      "Scraping the Job Offer 68 DONE.\n",
      "Scraping the Job Offer 69\n",
      "Scraping the Job Offer 69 DONE.\n",
      "Scraping the Job Offer 70\n",
      "Scraping the Job Offer 70 DONE.\n",
      "Scraping the Job Offer 71\n",
      "Scraping the Job Offer 71 DONE.\n",
      "Scraping the Job Offer 72\n",
      "Scraping the Job Offer 72 DONE.\n",
      "Scraping the Job Offer 73\n",
      "Scraping the Job Offer 73 DONE.\n",
      "Scraping the Job Offer 74\n",
      "Scraping the Job Offer 74\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=114.0.5735.134)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00348893+48451]\n\t(No symbol) [0x002DB8A1]\n\t(No symbol) [0x001E5058]\n\t(No symbol) [0x001CD073]\n\t(No symbol) [0x0022DEBB]\n\t(No symbol) [0x0023BFD3]\n\t(No symbol) [0x0022A0B6]\n\t(No symbol) [0x00207E08]\n\t(No symbol) [0x00208F2D]\n\tGetHandleVerifier [0x005A8E3A+2540266]\n\tGetHandleVerifier [0x005E8959+2801161]\n\tGetHandleVerifier [0x005E295C+2776588]\n\tGetHandleVerifier [0x003D2280+612144]\n\t(No symbol) [0x002E4F6C]\n\t(No symbol) [0x002E11D8]\n\t(No symbol) [0x002E12BB]\n\t(No symbol) [0x002D4857]\n\tBaseThreadInitThunk [0x767A00C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77E97B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77E97B1E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-a867fbf687a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# find the general information of the job offers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"job-view-layout\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=114.0.5735.134)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00348893+48451]\n\t(No symbol) [0x002DB8A1]\n\t(No symbol) [0x001E5058]\n\t(No symbol) [0x001CD073]\n\t(No symbol) [0x0022DEBB]\n\t(No symbol) [0x0023BFD3]\n\t(No symbol) [0x0022A0B6]\n\t(No symbol) [0x00207E08]\n\t(No symbol) [0x00208F2D]\n\tGetHandleVerifier [0x005A8E3A+2540266]\n\tGetHandleVerifier [0x005E8959+2801161]\n\tGetHandleVerifier [0x005E295C+2776588]\n\tGetHandleVerifier [0x003D2280+612144]\n\t(No symbol) [0x002E4F6C]\n\t(No symbol) [0x002E11D8]\n\t(No symbol) [0x002E12BB]\n\t(No symbol) [0x002D4857]\n\tBaseThreadInitThunk [0x767A00C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77E97B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77E97B1E+238]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# Create empty lists to store information\n",
    "job_titles = []\n",
    "company_names = []\n",
    "company_locations = []\n",
    "work_methods = []\n",
    "post_dates = []\n",
    "work_times = [] \n",
    "job_desc = []\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "# visit each link one by one to scrape the information\n",
    "print('Visiting the links and collecting information just started')\n",
    "for i in range(len(links)):\n",
    "    try:\n",
    "        driver.get(links[i])\n",
    "        i = i + 1\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        pass\n",
    "    # find the general information of the job offers\n",
    "\n",
    "    contents = driver.find_elements(By.CLASS_NAME,\"job-view-layout\")\n",
    "\n",
    "\n",
    "    for content in contents:\n",
    "        try:\n",
    "            job_titles.append(content.find_element(By.CLASS_NAME, \"display-flex\").text)\n",
    "            company_names.append(content.find_element(By.CLASS_NAME,\"jobs-unified-top-card__company-name\").text)\n",
    "            company_locations.append(content.find_element(By.CLASS_NAME,\"jobs-unified-top-card__bullet\").text)\n",
    "            work_methods.append(content.find_element(By.CLASS_NAME,\"jobs-unified-top-card__workplace-type\").text)\n",
    "            post_dates.append(content.find_element(By.CLASS_NAME,\"jobs-unified-top-card__posted-date\").text)\n",
    "            work_times.append(content.find_element(By.CLASS_NAME,\"jobs-unified-top-card__job-insight\").text)\n",
    "            print(f'Scraping the Job Offer {j} DONE.')\n",
    "            j+= 1\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(5)\n",
    "        # scraping the job description\n",
    "        \n",
    "        job_description = driver.find_elements(By.CLASS_NAME,'jobs-description__content')\n",
    "        for description in job_description:\n",
    "            job_text = description.find_element(By.CLASS_NAME,\"jobs-box__html-content\").text\n",
    "            job_desc.append(job_text)\n",
    "            print(f'Scraping the Job Offer {j}')\n",
    "            time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Creating the dataframe \n",
    "df = pd.DataFrame(list(zip(job_titles,company_names,\n",
    "                    company_locations,work_methods,\n",
    "                    post_dates,work_times)),\n",
    "                    columns =['job_title', 'company_name',\n",
    "                           'company_location','work_method',\n",
    "                           'post_date','work_time'])\n",
    "\n",
    "# Storing the data to csv file\n",
    "df.to_csv('job_offers.csv', index=False)\n",
    "\n",
    "# Output job descriptions to txt file\n",
    "with open('job_descriptions.txt', 'w',encoding=\"utf-8\") as f:\n",
    "    for line in job_desc:\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
